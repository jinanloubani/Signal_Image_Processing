{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Lenna.jpg'        \n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Canaletto.jpeg'\n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/MinotaureBruite.jpeg'\n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    if name=='Cartoon':\n",
    "        url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Cartoon.jpg'        \n",
    "        response = requests.get(url)\n",
    "        res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "print(\"Les images de référence pour Lenna à gauche et de Canaletto à droite : \")\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=400\n",
    "WT= pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray',width=size,height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2D(S,qmf,L,threshold):\n",
    "    Lmax=pywt.dwt_max_level(len(S),pywt.Wavelet(qmf).dec_len)\n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(S, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "    WTS=arr*(np.abs(arr)>threshold)\n",
    "    ncoeffs=(np.abs(arr)>threshold).sum()\n",
    "    \n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Srec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    return Srec,ncoeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3','sym2','sym3']\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "im_res,ncoeffs=ApproxOnd2D(im,'db2',6,2)\n",
    "hv.Raster(im_res).opts(**options)\n",
    "print(\"Le nombre de coefficient pour réaliser l'approximation non linéaire est de\", ncoeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    T = param.Integer(7,bounds=(1,10))\n",
    "    def view(self):\n",
    "        im_res,ncoeffs = ApproxOnd2D(imagesRef[self.image],self.wave,self.L,self.T)\n",
    "        options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "        return hv.Raster(im_res).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "approx2D = Approx2D()\n",
    "pn.Row(approx2D.param,approx2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous effectuons une approximation linéaire des deux images (Lenna et Canaletto) pour différents types d'ondelettes en précisant le niveaux L et le seuil T. \n",
    "\n",
    "Visuellement, l'approximation linéaire nous donne un résultat proche des images initiales. Nous constatons que la qualité de l'image est meilleure lorsque $L$ augmente. Mais il est assez difficile de juger de visu la quanlité de l'approximation. Nous devons donc faire appel au PNSR (Peak Signal to Noise Ratio) qui mesure la qualité de reconstruction de l'image compressée par rapport à l'image initiale.\n",
    "\n",
    "Il est défini par :\n",
    "$$ PSNR = 20 * log_{10}(\\frac{d}{EQM})$$\n",
    "avec\n",
    "    \n",
    "- d : la valeur maximale pour un pixel.\n",
    "    \n",
    "- EQM  : l'erreur quadratique moyenne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    \n",
    "    mse = np.mean( (Iref - I) ** 2 )\n",
    "    \n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    \n",
    "    Val_MAX = np.max(I)\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(S,qmf,L,N):\n",
    "    a,b=np.shape(S)\n",
    "    N1=a*b\n",
    "    Lmax=pywt.dwt_max_level(len(S),pywt.Wavelet(qmf).dec_len)\n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(S, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WT)\n",
    "    Ind=np.argsort(np.abs(arr))\n",
    "    WTS=np.zeros(N1)\n",
    "    WTS[Ind[N1-N:N1]]=arr[Ind[N1-N:N1]]\n",
    "    coeffs_from_arr=pywt.unravel_coeffs(WTS,coeff_slices, coeff_shapes)\n",
    "    \n",
    "    Srec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    p=PSNR(S,Srec)\n",
    "    return Srec,p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irec,p=ApproxOnd2nonlin(im,'db2',6,5000)\n",
    "hv.Image(Irec).opts(cmap='gray',width=400,height=400)\n",
    "PSNR(im,Irec)\n",
    "\n",
    "#print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx2Dnonlin(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    N = param.Integer(2000,bounds=(1,10000))\n",
    "  #  @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        im_res,ncoeffs = ApproxOnd2nonlin(imagesRef[self.image],self.wave,self.L,self.N)\n",
    "        psnr1=PSNR(imagesRef[self.image],im_res)\n",
    "        strp1=\"%2.2f\" % psnr1\n",
    "        te1='PSNR signal reconstruit = '\n",
    "        TN1=hv.Text(0.5,0.5,te1+strp1).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "        return pn.Row(hv.Raster(im_res).opts(**options),TN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx2Dnonlin = Approx2Dnonlin()\n",
    "pn.Row(approx2Dnonlin.param,approx2Dnonlin.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous constatons que lorsqu'on augmente la valeur de N, la qualité d'image augmente. Quand N est environ 5000, l'image reconstruit n'est pas mal reconstruit. Il est en de même de pour les valeurs de $L$. En effet, à $L=0$, la qualité de l'image reconstruite est extrêment mauvaise.    \n",
    "Concernant les bases, nous constatons globalement que pour les 2 images que la base $coif3$ semble donner donner le meilleur résultat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image':imagesRef,'N':np.linspace(1000,50000,30),'wave':wavelist}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences.values())),columns=experiences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def row2PSNR(row):\n",
    "    L=5\n",
    "    I,psnr=ApproxOnd2nonlin(imagesRef[row.Image],row.wave,L,int(row.N))\n",
    "    return {'PSNR':psnr}\n",
    "    \n",
    "rowtest =  dfexp.iloc[20]\n",
    "row2PSNR(rowtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfexp.apply(row2PSNR,axis=1)\n",
    "dfexp[['PSNR']] = pd.DataFrame.from_records(result.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dfexp.hvplot('N','PSNR',by='wave',kind='scatter',groupby=['Image'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(PSNR=(10,125),N=(800,51000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphe nous permet d'avoir un idée de l'effet de la valeur de $N$ et de la base de décomposition sur le PNSR et la reconstruction de l'image. \n",
    "\n",
    "On voit que pour les deux images, plus N augmente, plus PSNR augmente donc plus la qualité d'image reconstruit est bon. L'ondelette de \"coif3\" est la meilleure tandis que l'ondelette de \"Haar\" est la plus mauvaise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDurOndelettes(I,qmf,L,Seuil):\n",
    "    N1=np.shape(I)[0]*np.shape(I)[1]\n",
    "    Lmax=pywt.dwt_max_level(np.shape(I)[0],pywt.Wavelet(qmf).dec_len)\n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(I, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WT)\n",
    "    WTS=arr*(np.abs(arr)>Seuil)\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices, coeff_shapes)\n",
    "    Irec=np.clip(pywt.waverecn(coeffs_from_arr,qmf,mode='per'),0,255)\n",
    "    return Irec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(10,bounds=(1,100))\n",
    "    def view(self):\n",
    "        Iref=imagesRef[self.image]\n",
    "        Irec=SeuillageDurOndelettes(imagesRef[self.image],self.wave,self.L,self.Seuil)\n",
    "        options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "        return pn.Row(hv.Raster(Iref).opts(**options),hv.Raster(Irec).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaveSeuil=WaveSeuillage()\n",
    "pn.Column(WaveSeuil.param,WaveSeuil.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le seuillage en dur a pour effet de pixeliser l'image de départ. Cette fonction, permettant d'éliminer les petits variations du au bruit, nous permet de conserver que les coefficients nous permettant d'avoir le plus d'informations sur l'image initiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous effectuons un test sur des images non bruités. Nous constatons que plus le seuil est grand, moins la quantité de l'image est bonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(im)\n",
    "B=np.random.randn(n1,n2)\n",
    "sigma=10\n",
    "ib=im+sigma*B\n",
    "ib=np.clip(ib,0,255)\n",
    "hv.Image(ib).opts(cmap='gray',width=400,height=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitéeset débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveDebruit(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        Iref=imagesRef[self.image]\n",
    "        n1,n2=np.shape(Iref)\n",
    "        B=np.random.randn(n1,n2)\n",
    "        ib=Iref+self.Sigma*B\n",
    "        ib=np.clip(ib,0,255)\n",
    "        Irec=SeuillageDurOndelettes(ib,self.wave,self.L,sigma*self.Seuil)\n",
    "        psnr1=PSNR(imagesRef[self.image],Irec)\n",
    "        strp1=\"%2.2f\" % psnr1\n",
    "        strp2=\"%2.2f\" % PSNR(ib,Iref)\n",
    "        te1='PSNR Image reconstruit = '\n",
    "        te2='PSNR Image bruité = '\n",
    "        TN1=hv.Text(0.5,0.7,te1+strp1).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        TN2=hv.Text(0.5,0.5,te2+strp2).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        options = dict(cmap='gray',xaxis=None,yaxis=None,width=350,height=350,toolbar=None)\n",
    "        return pn.Row(pn.Column(hv.Raster(Iref).opts(**options),hv.Raster(ib).opts(**options),hv.Raster(Irec).opts(**options)),TN1*TN2)#,PSNR(Iref,ib),PSNR(Iref,Irec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaveDeb=WaveDebruit()\n",
    "pn.Row(WaveDeb.param,WaveDeb.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette expérience, nous avons 3 différentes images: la première est l'image originale, la deuxième l'image bruitée et la dernière l'image reconstruite. Nous allons observer les effets des différents paramètres sur le résultat du programme. Nous allons observer ces effets avec la base d'ondelettes $coif3$. \n",
    "\n",
    "En observant, les variations de PSNR suivant les valeurs du paramèttre $seuil$, nous constatons que le choix optimal est la valeur $3$, pour $sigma=10$. En effet, pour $seuil=3$, nous obtenons la plus grande valeur du PSNR. Néamoins, lorsque sigma varie, cette valeur change. Toutefois, la combinaision optimale de paramètres reste $seuil=3$ et $sigma=10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTranslation(IB,I,wave,seuil,NbT):\n",
    "    n1,n2=np.shape(IB)\n",
    "    Lmax=pywt.dwt_max_level(n1,pywt.Wavelet(wave).dec_len)\n",
    "    Isum=0*IB\n",
    "    P=np.zeros(NbT*NbT)\n",
    "    for i in range(0,NbT):\n",
    "        for j in range(0,NbT):\n",
    "            Ibt=np.roll(IB,(i,j))\n",
    "            Irectemp=SeuillageDurOndelettes(Ibt,wave,Lmax,seuil)\n",
    "            Irectemp2=np.roll(Irectemp,(-i,-j))\n",
    "            Isum=Isum+Irectemp2\n",
    "            Irec=Isum/(NbT*i+j+1)\n",
    "            P[NbT*i+j]=PSNR(Irec,I)\n",
    "    return Irec,P        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(im)\n",
    "B=np.random.randn(n1,n2)\n",
    "sigma=10\n",
    "ib=im+sigma*B\n",
    "ib=np.clip(ib,0,255)\n",
    "ir,PnSr=DebruitTranslation(ib,im,\"haar\",7,5)\n",
    "print(\"PNSR = \",PnSr)\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(ib).opts(**options),hv.Raster(ir).opts(**options))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(2,bounds=(1,8))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        seuil=3*self.Sigma\n",
    "        Iref=imagesRef[self.image]\n",
    "        n1,n2=np.shape(Iref)\n",
    "        np.random.seed(seed=self.seednoise)\n",
    "        B=np.random.randn(n1,n2)\n",
    "        ib=Iref+self.Sigma*B\n",
    "        ib=np.clip(ib,0,255)\n",
    "        Irec,Pns=DebruitTranslation(ib,Iref,self.wave,seuil,self.NbT)\n",
    "        options = dict(cmap='gray',xaxis=None,yaxis=None,width=350,height=350,toolbar=None)\n",
    "        strp1=\"%2.2f\" % Pns[-1]\n",
    "        strp2=\"%2.2f\" % PSNR(ib,Iref)\n",
    "        te1='PSNR Image reconstruit = '\n",
    "        te2='PSNR Image bruité = '\n",
    "        TN1=hv.Text(0.5,0.7,te1+strp1).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        TN2=hv.Text(0.5,0.5,te2+strp2).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        return pn.Row(pn.Column(hv.Raster(Iref).opts(**options),hv.Raster(ib).opts(**options),hv.Raster(Irec).opts(**options)),TN2*TN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deb_trans=Debruit_translat()\n",
    "pn.Row(Deb_trans.param,Deb_trans.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette expérience, nous avons 3 différentes images: la première est l'image originale, la deuxième l'image bruitée et la dernière l'image reconstruite. Nous constatons tout d'abord que le résultat obtenu est meilleur que pour la méthode précédente avec les mêmes paramètres en observant la valeur du PSNR. Nous constatons que le nombre optimal de translations à effectuer fortement de la valeur de $sigma$. Néanmoins, nous notons que la valeur du PNSR décroit à partir de $NbT \\geq 1$, puis croit.\n",
    "Avec cette méthode, à chaque translation, un débruitage d'une image est faite. Ainsi en faisant cela, nous obtenons un moyenne permettant d'aténuer le bruitage et de se rapprocher de l'image initiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=chargeData('Cartoon').astype('uint8')\n",
    "\n",
    "im2=chargeData('Minotaure').astype('uint8')\n",
    "\n",
    "imagesRef_col= {\"Minotaure\" : im2,\"Cartoon\" : im}\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "hv.RGB(im).opts(**options1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissnaces de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vraiu problème, il faut juste que les dimensions soit des multiples de puissances de \n",
    "2. C'est la puissance de 2 qui définira l'échalle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNRColor(im,iref):\n",
    "    mse = 0\n",
    "    Val_MAX = 0\n",
    "    for i in range (3):\n",
    "        mse += sum((np.ravel(iref[:,:,i] - im[:,:,i])) ** 2)\n",
    "        Val_MAX = max(Val_MAX, max(np.ravel(iref)))\n",
    "    mse = mse / 3 / iref.size\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "def periodique(I):\n",
    "    n1,n2 = np.shape(I)\n",
    "    im = np.zeros((2*n1,2*n2))\n",
    "    im[:n1,:n2] = I\n",
    "    im[n1:,:n2] = I\n",
    "    im[:n1,n2:] = I\n",
    "    im[n1:,n2:] = I\n",
    "    return im\n",
    "    \n",
    "def symetrique(I):\n",
    "    n1,n2 = np.shape(I)\n",
    "    im = np.zeros((2*n1,2*n2))\n",
    "    im[:n1,:n2] = I\n",
    "    im[n1:,:n2] = np.flipud(I)\n",
    "    im[:n1,n2:] = np.fliplr(I)\n",
    "    im[n1:,n2:] = I\n",
    "    return im   \n",
    "\n",
    "def EstimEcartTypeBruit(I,qmf):\n",
    "    n = np.shape(I)\n",
    "    Lmax=pywt.dwt_max_level(min(n[0],n[1]),pywt.Wavelet(qmf).dec_len)\n",
    "    wsb=pywt.wavedec(I, qmf, mode='per', level=Lmax)\n",
    "    mt=np.sqrt(2)*scp.special.erfinv(0.5)\n",
    "    return np.median(np.abs(wsb[Lmax]))/mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debruit_color(I,qmf,L,seuil):\n",
    "    I_debrui=np.copy(I)\n",
    "    n1,n2,n3=np.shape(I)\n",
    "    I_debrui[:,:,0]=SeuillageDurOndelettes(I[:,:,0],qmf,L,seuil)\n",
    "    I_debrui[:,:,1]=SeuillageDurOndelettes(I[:,:,1],qmf,L,seuil)\n",
    "    I_debrui[:,:,2]=SeuillageDurOndelettes(I[:,:,2],qmf,L,seuil)\n",
    "    return I_debrui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debruit(I,qmf,L,seuil):\n",
    "    I_debrui=np.copy(I)\n",
    "    I_debrui=SeuillageDurOndelettes(I,qmf,L,seuil)    \n",
    "    return I_debrui\n",
    "\n",
    "def debruit_color3(IB,qmf,per,L,seuil,sigma=None,):\n",
    "    n = np.shape(IB)\n",
    "    isImage = len(n) == 3\n",
    "    im = np.zeros(n)\n",
    "    #seuil = 3\n",
    "    if isImage :\n",
    "        #si image est colorée\n",
    "        for i in range(isImage*2+1):\n",
    "            #pour obtenir une image dont dimensions sont un multiple de 2\n",
    "            if per == 1 :\n",
    "                I = periodique(IB[:,:,i])\n",
    "            else :\n",
    "                I = symetrique(IB[:,:,i])\n",
    "            #pour evaluer le niveau de bruit\n",
    "            if sigma == None : \n",
    "                sigma = float(EstimEcartTypeBruit(IB[:,:,i],qmf))\n",
    "            #debruite en prenant un seuil de seuil* niveau de bruit\n",
    "            im_aux = debruit(I,qmf,L,seuil*sigma)\n",
    "            #pour retrovuer image de départ débuitee\n",
    "            im[:,:,i] = im_aux[:n[0],:n[1]]\n",
    "    else :\n",
    "        #si image est en niveau de gris\n",
    "        #estime le niveau de bruit\n",
    "        if sigma== None : \n",
    "            sigma = float(EstimEcartTypeBruit(IB,qmf))\n",
    "        #debruite en prenant un seuil de 3* niveau de bruit\n",
    "        im = debruit(IB,qmf,L,seuil*sigma)\n",
    "        #pour retrouver image de depart debruitee\n",
    "        im = im[:n[0],:n[1]]             \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2,n3=np.shape(im)\n",
    "bruitcouleur=np.random.randn(n1,n2,3)\n",
    "sigma=10\n",
    "imb=im+sigma*bruitcouleur\n",
    "im_re=debruit_color(imb,'db2',7,3*10)\n",
    "PSNR(im,im_re)\n",
    "hv.RGB(im_re.astype('uint8')).opts(**options1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveDebruit_col(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Cartoon\",objects=imagesRef_col.keys())\n",
    "    wave = param.ObjectSelector(default=\"db2\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    per=param.Integer(1,bounds=(1,2))\n",
    "    def view(self):\n",
    "        Iref=imagesRef_col[self.image]\n",
    "        n1,n2,n3=np.shape(Iref)\n",
    "        np.random.seed(seed=self.seednoise)\n",
    "        bruitcouleur=np.random.randn(n1,n2,3)\n",
    "        imb=Iref+self.Sigma*bruitcouleur\n",
    "        imb=np.clip(imb,0,255)\n",
    "        per=1\n",
    "        Irec=debruit_color3(imb,self.wave,self.per,self.L,self.Seuil,self.Sigma)\n",
    "        psnr1=PSNRColor(imagesRef_col[self.image],Irec)\n",
    "        strp1=\"%2.2f\" % psnr1\n",
    "        strp2=\"%2.2f\" % PSNRColor(imb,Iref)\n",
    "        te1='PSNR Image reconstruit = '\n",
    "        te2='PSNR Image bruité = '\n",
    "        TN1=hv.Text(0.5,0.7,te1+strp1).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        TN2=hv.Text(0.5,0.5,te2+strp2).opts(xaxis=None,yaxis=None,toolbar=None)\n",
    "        options=dict(width=350,height=350,xaxis=None,yaxis=None,toolbar=None)\n",
    "        return pn.Row(pn.Column(hv.RGB(Iref.astype('uint8')).opts(**options),hv.RGB(imb.astype('uint8')).opts(**options),hv.RGB(Irec.astype('uint8')).opts(**options)),TN2*TN1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaveDeb_col=WaveDebruit_col()\n",
    "pn.Row(WaveDeb_col.param,WaveDeb_col.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette expérience, nous avons 3 différentes images: la première est l'image originale, la deuxième l'image bruitée et la dernière l'image reconstruite. Globalement, nous notons une amélioration du PSNR et donc nous avons réussi à diminuer les effets du bruit. \n",
    "\n",
    "Nous constatons aussi que la méthode de prolongement par symétrie donne un résultat légèrement meilleur que la méthode par périodicité. Néanmoins les résultats restent très proche.\n",
    "\n",
    "\n",
    "\n",
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi=chargeData('Minotaure')\n",
    "Minotaure=np.clip(Mi,0,255)\n",
    "hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irec = debruit_color3(Minotaure,'db2',1,10,3)\n",
    "\n",
    "pn.Row(hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500),\n",
    "       hv.RGB(Irec.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PSNR image débruité : \",PSNRColor(Irec,Minotaure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier \n",
    "permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question.\n",
    "On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imagesRef.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_DebruitTrans = {'Image':imagesRef.keys(),'NbT':np.arange(1,5),'Sigma':np.linspace(10,30,2),'wave':wavelist}\n",
    "dfexp_DebruitTrans = pd.DataFrame(list(itertools.product(*experiences_DebruitTrans.values())),columns=experiences_DebruitTrans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTranslation2(IB,wave,seednoise,sigma,NbT):\n",
    "    n1,n2=np.shape(IB)\n",
    "    Lmax=pywt.dwt_max_level(n1,pywt.Wavelet(wave).dec_len)\n",
    "    Isum=0*IB\n",
    "    np.random.seed(seed=seednoise)\n",
    "    bruit=np.random.randn(n1,n2)\n",
    "    P=np.zeros(NbT*NbT)\n",
    "    seuil=3*sigma\n",
    "    IBb=IB+sigma*bruit\n",
    "    for i in range(0,NbT):\n",
    "        for j in range(0,NbT):\n",
    "            Ibt=np.roll(IBb,(i,j))\n",
    "            Irectemp=SeuillageDurOndelettes(Ibt,wave,Lmax,seuil)\n",
    "            Irectemp2=np.roll(Irectemp,(-i,-j))\n",
    "            Isum=Isum+Irectemp2\n",
    "            Irec=Isum/(NbT*i+j+1)\n",
    "            P[NbT*i+j]=PSNR(IB,Irec)\n",
    "    return Irec,P\n",
    "\n",
    "def Debruit_Translat_PSNRMoyen(I,wave,sigma,NbT,n):\n",
    "    P=np.zeros(NbT*NbT)\n",
    "    for seednoise in np.arange(0,n):\n",
    "        Irec,Ptemp=DebruitTranslation2(I,wave,seednoise,sigma,NbT)\n",
    "        P=P+Ptemp\n",
    "    P=P/n\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row):\n",
    "    psnr=Debruit_Translat_PSNRMoyen(imagesRef[row.Image],row.wave,row.Sigma,row.NbT,4)\n",
    "    return {'PSNR':psnr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultTrans = dfexp_DebruitTrans.apply(row2DebruitTrans,axis=1)\n",
    "dfexp_DebruitTrans[['PSNR']] = pd.DataFrame.from_records(resultTrans.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfexp_DebruitTrans.copy()\n",
    "\n",
    "df = pd.concat((df[['Image','NbT','wave','Sigma']],pd.DataFrame(df.PSNR.values.tolist(),df.index)),axis=1)\n",
    "\n",
    "df = df.melt(id_vars=['Image','NbT','wave','Sigma'],var_name='translation',value_name='PSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()\n",
    "df.hvplot('NbT','PSNR',by='wave',kind='scatter',groupby=['Image','Sigma'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(PSNR=(20,35),NbT=(-0.5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que plus $NbT$ augmente, plus est le PSNR est grand. Cela signifie que la même utilisée obtient de plus en plus de coefficients permettant de réduire l'effet du bruit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
